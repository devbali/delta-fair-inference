{
  "experiment": "abl3_share_100",
  "group": "ablation3",
  "server_cmd": [
    "docker",
    "run",
    "--rm",
    "--network",
    "host",
    "--runtime",
    "nvidia",
    "--gpus",
    "device=0",
    "--label",
    "ablation_run=1",
    "-v",
    "/:/hostroot",
    "-e",
    "NVIDIA_VISIBLE_DEVICES=0",
    "-e",
    "CUDA_VISIBLE_DEVICES=0",
    "-e",
    "HF_HOME=/home/devbali/.cache/huggingface",
    "-e",
    "CUDA_MPS_PIPE_DIRECTORY=/tmp/ablation-mps-pipe",
    "-e",
    "CUDA_MPS_LOG_DIRECTORY=/tmp/ablation-mps-log",
    "-e",
    "CUDA_MPS_ACTIVE_THREAD_PERCENTAGE=100",
    "ubuntu:24.04",
    "chroot",
    "/hostroot",
    "/bin/bash",
    "-lc",
    "cd /home/devbali/fairinf/delta-fair-inference && /home/devbali/fairinf/prefix-vtc-venv/bin/python /home/devbali/fairinf/delta-fair-inference/experiments/11-6-ablation/server.py --visible-device 0 --compute-share 100 --model-path meta-llama/Llama-3.1-8B --port 30000"
  ],
  "client_cmd": [
    "/home/devbali/fairinf/prefix-vtc-venv/bin/python",
    "/home/devbali/fairinf/delta-fair-inference/experiments/11-6-ablation/client.py",
    "--prompt-words",
    "10",
    "--completion-tokens",
    "1000",
    "--request-rate",
    "1",
    "--duration",
    "120",
    "--max-concurrent",
    "800"
  ],
  "success": true,
  "error": null,
  "timestamp": "2025-11-08T05:03:18",
  "artifacts": [
    "gpu_metrics_20251108_050043.csv",
    "token_usage_20251108_050043.csv",
    "latencies_20251108_050043.csv",
    "sglang_log_decode.csv"
  ]
}